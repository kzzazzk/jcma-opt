{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1 - Juego de coordinación multi-acción (JCMA)\n",
    "\n",
    "## Introducción\n",
    "\n",
    "En esta práctica trabajaremos con un juego estático y simétrico en estrategias, donde dos jugadores eligen simultáneamente un número entero en el conjunto $S = \\{0,1,2,3,4,5\\}$. Si la suma de ambas elecciones no supera un umbral (5), cada jugador obtiene exactamente lo que ha pedido; si lo supera, ambos reciben 0. Este juego presenta múltiples equilibrios puros que maximizan el bienestar social, pero con distintos grados de equidad entre jugadores. Las estrategias son simétricas, en el sentido de que ambos jugadores comparten el mismo conjunto de acciones. Los resultados cuya suma es 5 son eficientes (maximizan la suma de pagos), pero reparten beneficios de forma desigual.\n",
    "\n",
    "Más abajo encontrarás su definición formal y su matriz de pagos en forma normal, que usaremos como base para el análisis y la implementación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción de la práctica\n",
    "\n",
    "**¡Importante!** Revisa el juego de [Nicky Case](https://ncase.me/trust/) llamado *The Evolution of Trust* (~30min). Aunque originalmente sobre el Dilema del Prisionero Iterado (DPI), sus conceptos sobre cooperación, estrategias reactivas y dinámicas evolutivas son directamente aplicables a nuestro juego de suma limitada iterado. \n",
    "\n",
    "En nuestro caso, el juego es simultáneo y repetido: en cada ronda, los jugadores eligen acciones sin conocer la del rival, pero con acceso al historial completo de interacciones pasadas. Esto introduce complejidades como coordinación implícita, retaliación y evolución de normas sociales, haciendo de este juego un \"dilema más complejo\" que el DPI clásico (más acciones, umbral de suma, y payoffs asimétricos en equidad).\n",
    "\n",
    "La práctica tiene dos partes:\n",
    " - Parte 1: Montar la estructura computacional que permita simular torneos del juego de suma limitada iterado.\n",
    " - Parte 2: Diseñar una estrategia para un torneo de tres fases (enfrentamiento directo, evolutivo, y en ecosistema ampliado)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición formal del JCMA\n",
    "\n",
    "- Jugadores: P1, P2.\n",
    "- Acciones posibles: $S = \\{0,1,2,3,4,5\\}$.\n",
    "- Funciones de pago: sea $i$ la acción escogida por el jugador P1 y $j$ la acción escogida por el jugador P2, se define $u_1$ y $u_2$ como los pagos que obtiene el jugador P1 y P2 respectivamente:\n",
    "\n",
    "$$\n",
    " u_1(i,j)=\\begin{cases}\n",
    " i, & \\text{si } i+j\\le 5,\\\\\n",
    " 0, & \\text{si } i+j>5,\n",
    " \\end{cases}\n",
    " \\qquad\n",
    " u_2(i,j)=\\begin{cases}\n",
    " j, & \\text{si } i+j\\le 5,\\\\\n",
    " 0, & \\text{si } i+j>5.\n",
    " \\end{cases}\n",
    "$$\n",
    "\n",
    "Es decir cada jugador obtiene *\"lo que pide\"*, a no ser que la suma de lo que todos piden sea mayor que 5, en cuyo caso nadie gana nada.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de pagos\n",
    "\n",
    "Por filas la acción del jugador P1, por columnas la acción del jugador P2.\n",
    "\n",
    "<center>\n",
    "\n",
    "|   i\\j |     0 |     1 |     2 |     3 |         4 |         5 |\n",
    "| ----: | ----: | ----: | ----: | ----: | --------: | --------: |\n",
    "| **0** | (0,0) | (0,1) | (0,2) | (0,3) |   (0,4)   |   (0,5)   |\n",
    "| **1** | (1,0) | (1,1) | (1,2) | (1,3) |   (1,4)   |   (0,0)   |\n",
    "| **2** | (2,0) | (2,1) | (2,2) | (2,3) |   (0,0)   |   (0,0)   |\n",
    "| **3** | (3,0) | (3,1) | (3,2) | (0,0) |   (0,0)   |   (0,0)   |\n",
    "| **4** | (4,0) | (4,1) | (0,0) | (0,0) |   (0,0)   |   (0,0)   |\n",
    "| **5** | (5,0) | (0,0) | (0,0) | (0,0) |   (0,0)   |   (0,0)   |\n",
    "\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Software para el estudio del JCMA\n",
    "\n",
    "El primer objetivo es crear un software que permita simular torneos del juego definido arriba en las versiones \"enfrentamiento directo\" y  \"evolutiva\".\n",
    "\n",
    "Requisitos mínimos:\n",
    "\n",
    "- Programado en Python >3.8, utilizando programación orientada a objetos (OOP).\n",
    "- Entradas para el torneo de enfrentamiento directo:\n",
    "  - `all_players`: lista o tupla de jugadores participantes (con su estrategia).\n",
    "  - `game`: objeto que define el juego (conjunto de acciones S={0..5}, umbral T=5 y función de pagos u1,u2).\n",
    "  - `repetitions`: número de veces que una estrategia se enfrenta a otra.\n",
    "  - `noise` (opcional): probabilidad de ejecución errónea de la acción elegida.\n",
    "- Salidas: información (visual) del resultado del campeonato (ranking y puntuaciones agregadas).\n",
    "- Incluir al menos estrategias básicas: `AlwaysK` para K∈{0,1,2,3,4,5} y `UniformRandom`. Debe ser sencillo añadir nuevas estrategias.\n",
    "\n",
    "Estructura de proyecto recomendada (solo si piensas trabajar en local, si usas este notebook como lugar de trabajo, ignórala):\n",
    "\n",
    "```\n",
    ".\n",
    "└── limited_sum/\n",
    "    ├── limited_sum/\n",
    "    │   ├── __init__.py\n",
    "    │   ├── game.py        # define S, T y la función de pagos u1,u2\n",
    "    │   ├── player.py      # clase base Player y estrategias básicas (AlwaysK, Random)\n",
    "    │   ├── match.py       # partida one-shot entre dos jugadores y registro de payoffs\n",
    "    │   ├── tournament.py  # lógica del torneo todos-contra-todos\n",
    "    │   └── evolution.py   # dinámica evolutiva\n",
    "    ├── main.py\n",
    "    └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plantilla de desarrollo\n",
    "\n",
    "A continuación se propone una **plantilla de desarrollo** con los módulos/clases que se recomienda implementar para resolver este problema. No es obligatorio seguir esta estructura, pero a falta de mejores ideas, puede ser un buen punto de partida.\n",
    "\n",
    "Para facilitar la tarea de identificar qué métodos faltan por implementar, en todos ellos se ha incluido la excepción ```raise NotImplementedError``` para poner de manifiesto que dicho método debe ser implementado.\n",
    "\n",
    "El uso de librerías **basicas** está permitido, siempre que esté justificado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from typing import Self, Sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El módulo ```game```\n",
    "\n",
    "El primer módulo que se recomienda implementar es el que recoge la información sobre el juego. Como nuestro juego tiene 6 acciones posibles (0 a 5), por simplicidad crearemos constantes para representarlas. El umbral de suma es THRESHOLD=5. Representarán estas acciones a lo largo de todo el código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acciones del juego de suma limitada\n",
    "ACTIONS = (0, 1, 2, 3, 4, 5)\n",
    "THRESHOLD = 5  # Umbral de suma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se propone implementar una clase llamada ```Game``` para representar el juego de suma limitada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "\n",
    "class Game:\n",
    "\n",
    "    def __init__(self, actions: Sequence[int] = ACTIONS, threshold: int = THRESHOLD):\n",
    "        \"\"\"\n",
    "        Represents the limited-sum game.\n",
    "\n",
    "        Parameters:\n",
    "            - actions (list[int]): list of possible actions (default: [0,1,2,3,4,5])\n",
    "            - threshold (int): sum threshold beyond which both get 0 (default: 5)\n",
    "        \"\"\"\n",
    "        self.actions = actions\n",
    "        self.threshold = threshold\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def payoff_matrix(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Payoff matrix of the game.\n",
    "\n",
    "        Returns:\n",
    "            - 6x6 np array of the matrix\n",
    "        \"\"\"\n",
    "        N = len(self.actions)\n",
    "        \n",
    "        matrix = np.empty((N, N), dtype=object)\n",
    "\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                if i + j <= self.threshold:\n",
    "                    matrix[i, j] = (i, j)\n",
    "                else:\n",
    "                    matrix[i, j] = (0, 0)\n",
    "        \n",
    "        return matrix   \n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def evaluate_result(self, a_1: int, a_2: int) -> tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Given two actions, returns the payoffs of the two players.\n",
    "\n",
    "        Parameters:\n",
    "            - a_1 (int): action of player 1 (0 to 5)\n",
    "            - a_2 (int): action of player 2 (0 to 5)\n",
    "\n",
    "        Returns:\n",
    "            - tuple of two floats, being the first and second values the payoff\n",
    "            for the first and second player, respectively.\n",
    "        \"\"\"\n",
    "        payoff = self.payoff_matrix\n",
    "        return payoff[a_1, a_2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprueba que los métodos anteriores funcionan correctamente con el siguiente test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0) -> (0, 0)\n",
      "(0, 1) -> (0, 1)\n",
      "(0, 2) -> (0, 2)\n",
      "(0, 3) -> (0, 3)\n",
      "(0, 4) -> (0, 4)\n",
      "(0, 5) -> (0, 5)\n",
      "(1, 0) -> (1, 0)\n",
      "(1, 1) -> (1, 1)\n",
      "(1, 2) -> (1, 2)\n",
      "(1, 3) -> (1, 3)\n",
      "(1, 4) -> (1, 4)\n",
      "(1, 5) -> (0, 0)\n",
      "(2, 0) -> (2, 0)\n",
      "(2, 1) -> (2, 1)\n",
      "(2, 2) -> (2, 2)\n",
      "(2, 3) -> (2, 3)\n",
      "(2, 4) -> (0, 0)\n",
      "(2, 5) -> (0, 0)\n",
      "(3, 0) -> (3, 0)\n",
      "(3, 1) -> (3, 1)\n",
      "(3, 2) -> (3, 2)\n",
      "(3, 3) -> (0, 0)\n",
      "(3, 4) -> (0, 0)\n",
      "(3, 5) -> (0, 0)\n",
      "(4, 0) -> (4, 0)\n",
      "(4, 1) -> (4, 1)\n",
      "(4, 2) -> (0, 0)\n",
      "(4, 3) -> (0, 0)\n",
      "(4, 4) -> (0, 0)\n",
      "(4, 5) -> (0, 0)\n",
      "(5, 0) -> (5, 0)\n",
      "(5, 1) -> (0, 0)\n",
      "(5, 2) -> (0, 0)\n",
      "(5, 3) -> (0, 0)\n",
      "(5, 4) -> (0, 0)\n",
      "(5, 5) -> (0, 0)\n"
     ]
    }
   ],
   "source": [
    "# Prints all possible outcomes of the limited-sum game\n",
    "game = Game(actions=ACTIONS, threshold=THRESHOLD)\n",
    "possible_actions = ACTIONS\n",
    "for a1, a2 in itertools.product(possible_actions, repeat=2):\n",
    "    print(f\"{(a1, a2)} -> {game.evaluate_result(a1, a2)}\")\n",
    "\n",
    "# Output:\n",
    "# (0, 0) -> (0, 0)\n",
    "# (0, 1) -> (0, 1)\n",
    "# ...\n",
    "# (5, 5) -> (0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El módulo ```player```\n",
    "\n",
    "Ahora vamos a programar un módulo que sirva para representar a los jugadores. En particular, su método principal será ```strategy()```, que devolverá una acción a realizar, en base a la historia de interacción con otro jugador. Además, aprovecharemos a implementar estrategias básicas, para que luego sea sencillo hacer pruebas. Algunas de estas estrategias tienen soluciones abiertas: por el momento, implementa lógicas sencillas, ya que estas estrategias se usarán para testeo exclusivamente.\n",
    "\n",
    "Empezaremos programando una clase abstracta llamada ```Player``` de la que heredarán los jugadores concretos que programaremos a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player(ABC):\n",
    "\n",
    "    # Este método ya está implementado\n",
    "    @abstractmethod\n",
    "    def __init__(self, game: Game, name: str = \"\"):\n",
    "        \"\"\"\n",
    "        Abstract class that represents a generic player\n",
    "\n",
    "        Parameters:\n",
    "            - name (str): the name of the strategy\n",
    "            - game (Game): the game that this player will play\n",
    "        \"\"\"\n",
    "\n",
    "        self.name = name\n",
    "        self.game = game\n",
    "\n",
    "        self.history  = []  # This is the main variable of this class. It is\n",
    "                            # intended to store all the history of actions\n",
    "                            # performed by this player.\n",
    "                            # Example: [0, 1, 2, 3] <- So far, the\n",
    "                            # interaction lasts four rounds. In the first one,\n",
    "                            # this player chose 0. In the second, 1. Etc.\n",
    "\n",
    "\n",
    "    # Este método ya está implementado\n",
    "    @abstractmethod\n",
    "    def strategy(self, opponent: Self) -> int:\n",
    "        \"\"\"\n",
    "        Main call of the class. Gives the action for the following round of the\n",
    "        interaction, based on the history\n",
    "\n",
    "        Parameters:\n",
    "            - opponent (Player): is another instance of Player.\n",
    "\n",
    "        Results:\n",
    "            - An integer representing the action (0 to 5)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def compute_scores(self, opponent: Self) -> tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Compute the scores for a given opponent\n",
    "\n",
    "        Parameters:\n",
    "            - opponent (Player): is another instance of Player.\n",
    "\n",
    "        Results:\n",
    "            - A tuple of two floats, where the first value is the current\n",
    "            player's payoff, and the second value is the opponent's payoff.\n",
    "        \"\"\"\n",
    "        total_payoff = (0.0 , 0.0)\n",
    "\n",
    "        for i, move in enumerate(self.history):\n",
    "            current_payoff = self.game.evaluate_result(move, opponent.history[i])\n",
    "            total_payoff = np.add(np.array(total_payoff), np.array(current_payoff)).tolist()\n",
    "            \n",
    "        return total_payoff\n",
    "\n",
    "    # Este método ya está implementado\n",
    "    def clean_history(self):\n",
    "        \"\"\"Resets the history of the current player\"\"\"\n",
    "        self.history = []\n",
    "\n",
    "\n",
    "# A continuación se representan las estrategias básicas para el juego de suma limitada\n",
    "\n",
    "class Always0(Player):\n",
    "\n",
    "    def __init__(self, game: Game, name: str = \"\"):\n",
    "        \"\"\"Always chooses 0\"\"\"\n",
    "        super().__init__(game=game, name=name)\n",
    "\n",
    "    def strategy(self, opponent: Player) -> int:\n",
    "        \"\"\"Always chooses 0\"\"\"\n",
    "        return 0\n",
    "\n",
    "class Always3(Player):\n",
    "\n",
    "    def __init__(self, game: Game, name: str = \"\"):\n",
    "        \"\"\"Always chooses 3\"\"\"\n",
    "        super().__init__(game=game, name=name)\n",
    "\n",
    "\n",
    "    def strategy(self, opponent: Player) -> int:\n",
    "        \"\"\"Always chooses 3\"\"\"\n",
    "        return 3\n",
    "\n",
    "class UniformRandom(Player):\n",
    "\n",
    "    def __init__(self, game: Game, name: str = \"\"):\n",
    "        \"\"\"Chooses uniformly at random\"\"\"\n",
    "        super().__init__(game=game, name=name)\n",
    "\n",
    "    def strategy(self, opponent: Player) -> int:\n",
    "        \"\"\"Chooses uniformly at random\"\"\"\n",
    "        return random.randint(0,5)\n",
    "\n",
    "class Focal5(Player):\n",
    "\n",
    "    def __init__(self, game: Game, name: str = \"\"):\n",
    "        \"\"\"Tries to coordinate on i+j=5. Several logics possible.\"\"\"\n",
    "        super().__init__(game=game, name=name)\n",
    "\n",
    "\n",
    "    def strategy(self, opponent: Player) -> int:\n",
    "        \"\"\"First round: 2, then adapts based on opponent trying to maximize the\n",
    "        chances of establishing a 5-way split in each round.\"\"\"\n",
    "        if(len(self.history) == 0):\n",
    "            move = 2\n",
    "        else:\n",
    "            move = 5 - opponent.history[-1]\n",
    "\n",
    "        return move\n",
    "\n",
    "class TitForTat(Player):\n",
    "\n",
    "    def __init__(self, game: Game, name: str = \"\"):\n",
    "        \"\"\"Tit-for-tat adapted to the JCMA. Several logics possible.\"\"\"\n",
    "        super().__init__(game=game, name=name)\n",
    "\n",
    "\n",
    "    def strategy(self, opponent: Player) -> int:\n",
    "        \"\"\"Similar to Focal5, but reactive with opponent's actions above 3.\"\"\"\n",
    "        move = 2 # Si es el primer movimiento\n",
    "        if(len(self.history) > 0):\n",
    "            if(opponent.history[-1] > 3):\n",
    "                move = opponent.history[-1]\n",
    "            else:\n",
    "                move = 2       \n",
    "        return move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testearemos este módulo una vez programemos el siguiente\n",
    "\n",
    "#### El módulo ```match```\n",
    "\n",
    "Ya sabemos manejar jugadores. Ahora vamos a enfrentarles. El presente módulo pretende recoger las herramientas necesarias para enfrentar a dos jugadores en una *partida* del JCMA. Está compuesto por una clase llamada ```Match``` que implementa el método principal ```play()```. Incluye el mecanismo de *\"error\"*: aleatoriamente para cada jugador y ronda, con una cierta probabilidad `error`, la acción del jugador $a$ será cambiada por su complementaria:\n",
    " - 0 ↔ 5\n",
    " - 1 ↔ 4\n",
    " - 2 ↔ 3\n",
    " - 3 ↔ 2\n",
    " - 4 ↔ 1\n",
    " - 5 ↔ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Match:\n",
    "\n",
    "    # Este método ya está implementado\n",
    "    def __init__(self, player_1: Player,\n",
    "                       player_2: Player,\n",
    "                       n_rounds: int = 100,\n",
    "                       error: float = 0.0):\n",
    "        \"\"\"\n",
    "        Match class to represent an iterative limited-sum game\n",
    "\n",
    "        Parameters:\n",
    "            - player_1 (Player): first player of the match\n",
    "            - player_2 (Player): second player of the match\n",
    "            - n_rounds (int = 100): number of rounds in the match\n",
    "            - error (float = 0.0): error probability (on a 0-1 scale).\n",
    "        \"\"\"\n",
    "\n",
    "        assert n_rounds > 0, \"'n_rounds' should be greater than 0\"\n",
    "\n",
    "        self.player_1 = player_1\n",
    "        self.player_2 = player_2\n",
    "        self.n_rounds = n_rounds\n",
    "        self.error = error\n",
    "\n",
    "        self.score = (0.0, 0.0)  # this variable will store the final result of\n",
    "                                 # the match, once the 'play()' function has\n",
    "                                 # been called. The two values of the tuple\n",
    "                                 # correspond to the points scored by the first\n",
    "                                 # and second player, respectively.\n",
    "\n",
    "\n",
    "    def complement_action(self, action: int) -> int:\n",
    "        \"\"\"\n",
    "        Return the complementary action for error mechanism\n",
    "\n",
    "        Parameters\n",
    "            - action (int): The action on which the complementary\n",
    "            operation will be calculated.\n",
    "        \"\"\"\n",
    "        complement = {0:5, 1:4, 2:3, 3:2, 4:1, 5:0}\n",
    "        return complement[action]\n",
    "\n",
    "    \n",
    "    def play(self, do_print: bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Main call of the class. Play the match.\n",
    "        Stores the final result in 'self.score'\n",
    "\n",
    "        Parameters\n",
    "            - do_print (bool = False): if True, should print the ongoing\n",
    "            results at the end of each round (i.e. print round number, last\n",
    "            actions of both players and ongoing score).\n",
    "        \"\"\"\n",
    "        if do_print:\n",
    "            print(\"##############################\")\n",
    "            print(f\"PARTIDO {self.player_1.name} VS {self.player_2.name}\")\n",
    "            print(\"##############################\")\n",
    "\n",
    "        self.player_1.clean_history()\n",
    "        self.player_2.clean_history()\n",
    "        \n",
    "        for i in range(self.n_rounds):\n",
    "            r1 = self.player_1.strategy(self.player_2)\n",
    "            r2 = self.player_2.strategy(self.player_1)\n",
    "\n",
    "            if random.random() < self.error:\n",
    "                r1 = self.complement_action(r1)\n",
    "            if random.random() < self.error:\n",
    "                r2 = self.complement_action(r2)\n",
    "\n",
    "            self.player_1.history.append(r1)\n",
    "            self.player_2.history.append(r2)\n",
    "\n",
    "            payoff = self.player_1.game.evaluate_result(r1, r2)\n",
    "\n",
    "            self.score = (self.score[0] + payoff[0], self.score[1] + payoff[1])\n",
    "\n",
    "            if do_print:\n",
    "                print(f\" >>> ROUND {i+1}\")    \n",
    "                print(\"Player 1 action:\", r1)\n",
    "                print(\"Player 2 action:\", r2)\n",
    "                print(\"Round payoff:\", payoff)\n",
    "                print(\"Acumulated total score:\", self.score)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprueba que los últimos dos módulos funcionan como se espera en la siguiente celda. Experimenta con distintas combinaciones de jugadores y observa que los resultados son los esperados. Por ejemplo, un Always0 y un Focal5 deberían coordinarse en (0,5) tras la primera ronda, obteniendo 0 y 5 puntos respectivamente por ronda. Comprueba también que el error se está tratando como corresponde. Por ejemplo, fíjalo en un valor alto (e.g. 0.2) y observa cómo las acciones pueden cambiar aleatoriamente. Comprueba también que puedes enfrentar dos jugadores que jueguen la misma estrategia (simplemente crea dos instancias del mismo jugador, con distintos nombres)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################\n",
      "PARTIDO always0 VS focal5\n",
      "##############################\n",
      " >>> ROUND 1\n",
      "Player 1 action: 0\n",
      "Player 2 action: 2\n",
      "Round payoff: (0, 2)\n",
      "Acumulated total score: (0.0, 2.0)\n",
      " >>> ROUND 2\n",
      "Player 1 action: 0\n",
      "Player 2 action: 5\n",
      "Round payoff: (0, 5)\n",
      "Acumulated total score: (0.0, 7.0)\n",
      " >>> ROUND 3\n",
      "Player 1 action: 0\n",
      "Player 2 action: 5\n",
      "Round payoff: (0, 5)\n",
      "Acumulated total score: (0.0, 12.0)\n",
      " >>> ROUND 4\n",
      "Player 1 action: 0\n",
      "Player 2 action: 5\n",
      "Round payoff: (0, 5)\n",
      "Acumulated total score: (0.0, 17.0)\n",
      " >>> ROUND 5\n",
      "Player 1 action: 0\n",
      "Player 2 action: 5\n",
      "Round payoff: (0, 5)\n",
      "Acumulated total score: (0.0, 22.0)\n",
      " >>> ROUND 6\n",
      "Player 1 action: 0\n",
      "Player 2 action: 5\n",
      "Round payoff: (0, 5)\n",
      "Acumulated total score: (0.0, 27.0)\n",
      " >>> ROUND 7\n",
      "Player 1 action: 0\n",
      "Player 2 action: 5\n",
      "Round payoff: (0, 5)\n",
      "Acumulated total score: (0.0, 32.0)\n",
      " >>> ROUND 8\n",
      "Player 1 action: 0\n",
      "Player 2 action: 5\n",
      "Round payoff: (0, 5)\n",
      "Acumulated total score: (0.0, 37.0)\n",
      " >>> ROUND 9\n",
      "Player 1 action: 0\n",
      "Player 2 action: 5\n",
      "Round payoff: (0, 5)\n",
      "Acumulated total score: (0.0, 42.0)\n",
      " >>> ROUND 10\n",
      "Player 1 action: 0\n",
      "Player 2 action: 5\n",
      "Round payoff: (0, 5)\n",
      "Acumulated total score: (0.0, 47.0)\n",
      "##############################\n",
      "PARTIDO always3 VS always3_2\n",
      "##############################\n",
      " >>> ROUND 1\n",
      "Player 1 action: 3\n",
      "Player 2 action: 3\n",
      "Round payoff: (0, 0)\n",
      "Acumulated total score: (0.0, 0.0)\n",
      " >>> ROUND 2\n",
      "Player 1 action: 2\n",
      "Player 2 action: 3\n",
      "Round payoff: (2, 3)\n",
      "Acumulated total score: (2.0, 3.0)\n",
      " >>> ROUND 3\n",
      "Player 1 action: 3\n",
      "Player 2 action: 3\n",
      "Round payoff: (0, 0)\n",
      "Acumulated total score: (2.0, 3.0)\n",
      " >>> ROUND 4\n",
      "Player 1 action: 3\n",
      "Player 2 action: 2\n",
      "Round payoff: (3, 2)\n",
      "Acumulated total score: (5.0, 5.0)\n",
      " >>> ROUND 5\n",
      "Player 1 action: 3\n",
      "Player 2 action: 3\n",
      "Round payoff: (0, 0)\n",
      "Acumulated total score: (5.0, 5.0)\n",
      " >>> ROUND 6\n",
      "Player 1 action: 3\n",
      "Player 2 action: 3\n",
      "Round payoff: (0, 0)\n",
      "Acumulated total score: (5.0, 5.0)\n",
      " >>> ROUND 7\n",
      "Player 1 action: 3\n",
      "Player 2 action: 3\n",
      "Round payoff: (0, 0)\n",
      "Acumulated total score: (5.0, 5.0)\n",
      " >>> ROUND 8\n",
      "Player 1 action: 3\n",
      "Player 2 action: 3\n",
      "Round payoff: (0, 0)\n",
      "Acumulated total score: (5.0, 5.0)\n",
      "##############################\n",
      "PARTIDO random VS tft\n",
      "##############################\n",
      " >>> ROUND 1\n",
      "Player 1 action: 1\n",
      "Player 2 action: 2\n",
      "Round payoff: (1, 2)\n",
      "Acumulated total score: (1.0, 2.0)\n",
      " >>> ROUND 2\n",
      "Player 1 action: 1\n",
      "Player 2 action: 2\n",
      "Round payoff: (1, 2)\n",
      "Acumulated total score: (2.0, 4.0)\n",
      " >>> ROUND 3\n",
      "Player 1 action: 4\n",
      "Player 2 action: 2\n",
      "Round payoff: (0, 0)\n",
      "Acumulated total score: (2.0, 4.0)\n",
      " >>> ROUND 4\n",
      "Player 1 action: 5\n",
      "Player 2 action: 4\n",
      "Round payoff: (0, 0)\n",
      "Acumulated total score: (2.0, 4.0)\n",
      " >>> ROUND 5\n",
      "Player 1 action: 0\n",
      "Player 2 action: 5\n",
      "Round payoff: (0, 5)\n",
      "Acumulated total score: (2.0, 9.0)\n"
     ]
    }
   ],
   "source": [
    "game = Game()\n",
    "\n",
    "always0_player = Always0(game, \"always0\")\n",
    "always3_player = Always3(game, \"always3\")\n",
    "random_player = UniformRandom(game, \"random\")\n",
    "focal5_player = Focal5(game, \"focal5\")\n",
    "tft_player = TitForTat(game, \"tft\")\n",
    "\n",
    "match = Match(always0_player, focal5_player, n_rounds=10, error=0.0)\n",
    "match.play(do_print=True)\n",
    "\n",
    "match2 = Match(always3_player, Always3(game, \"always3_2\"), n_rounds=8, error=0.2)\n",
    "match2.play(do_print=True)\n",
    "\n",
    "match2 = Match(random_player, tft_player, n_rounds=5, error=0.0)\n",
    "match2.play(do_print=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El módulo ```tournament```\n",
    "\n",
    "Finalmente, llegamos al módulo que nos va a permitir simular el campeonato. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tournament:\n",
    "\n",
    "    # Este método ya está implementado\n",
    "    def __init__(self, players: tuple[Player, ...],\n",
    "                       n_rounds: int = 100,\n",
    "                       error: float = 0.0,\n",
    "                       repetitions: int = 2):\n",
    "        \"\"\"\n",
    "        All-against-all tournament\n",
    "\n",
    "        Parameters:\n",
    "            - players (tuple[Player, ...]): tuple of players that will play the\n",
    "         tournament\n",
    "            - n_rounds (int = 100): number of rounds in each match\n",
    "            - error (float = 0.0): error probability (in base 1)\n",
    "            - repetitions (int = 2): number of matches each player plays against\n",
    "         each other player\n",
    "        \"\"\"\n",
    "\n",
    "        self.players = players\n",
    "        self.n_rounds = n_rounds\n",
    "        self.error = error\n",
    "        self.repetitions = repetitions\n",
    "\n",
    "        # This is a key variable of the class. It is intended to store the\n",
    "        # ongoing ranking of the tournament. It is a dictionary whose keys are\n",
    "        # the players in the tournament, and its corresponding values are the\n",
    "        # points obtained in their interactions with each other. In the end, to\n",
    "        # see the winner, it will be enough to sort this dictionary by the\n",
    "        # values.\n",
    "        self.ranking = {player: 0.0 for player in self.players}  # initial vals\n",
    "\n",
    "\n",
    "    def sort_ranking(self) -> None:\n",
    "        \"\"\"Sort the ranking by the value (score)\"\"\"\n",
    "        self.ranking = dict(sorted(self.ranking.items(), key=lambda item: item[1], reverse=True))\n",
    "        \n",
    "\n",
    "    #pista: utiliza 'itertools.combinations' para hacer los cruces\n",
    "    def play(self) -> None:\n",
    "        \"\"\"\n",
    "        Main call of the class. It must simulate the championship and update\n",
    "        the variable 'self.ranking' with the accumulated points obtained by\n",
    "        each player in their interactions.\n",
    "        \"\"\"\n",
    "        self.ranking = {player: 0.0 for player in self.players}\n",
    "\n",
    "        for p1, p2 in itertools.combinations(self.players, 2):\n",
    "            for _ in range(self.repetitions):\n",
    "                match = Match(p1, p2, n_rounds=self.n_rounds, error=self.error)\n",
    "                match.play(do_print=False)\n",
    "                self.ranking[p1] += match.score[0]\n",
    "                self.ranking[p2] += match.score[1]\n",
    "                \n",
    "        self.sort_ranking()\n",
    "\n",
    "    def plot_results(self):\n",
    "        \"\"\"\n",
    "        Plots a bar chart of the final ranking. On the x-axis should appear\n",
    "        the names of the sorted ranking of players participating in the\n",
    "        tournament. On the y-axis the points obtained.\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        names = [player.name for player in self.ranking.keys()]\n",
    "        scores = list(self.ranking.values())\n",
    "        \n",
    "        plt.figure(figsize=(10,5))\n",
    "        plt.bar(names, scores, color='skyblue')\n",
    "        plt.xlabel(\"Players\")\n",
    "        plt.ylabel(\"Points\")\n",
    "        plt.title(\"Tournament \")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testear la implementación, prueba un torneo con las estrategias básicas del juego de suma limitada. Por ejemplo, con 10 rondas por interacción y sin error. Observa cómo diferentes estrategias obtienen diferentes puntuaciones según su capacidad para coordinarse en equilibrios eficientes o explotar a rivales cooperativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "game = Game()\n",
    "\n",
    "always0_player = Always0(game, \"always0\")\n",
    "always3_player = Always3(game, \"always3\")\n",
    "random_player = UniformRandom(game, \"random\")\n",
    "focal5_player = Focal5(game, \"focal5\")\n",
    "tft_player = TitForTat(game, \"tft\")\n",
    "\n",
    "all_players = (always0_player, always3_player, random_player, focal5_player,\n",
    "               tft_player)\n",
    "\n",
    "tournament = Tournament(all_players, n_rounds=100, error=0.0, repetitions=1)\n",
    "tournament.play()\n",
    "tournament.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El módulo ```evolution```\n",
    "\n",
    "A continuación se presenta la variante evolutiva del torneo, similar a la que se explica en la sección \"4. Repeated Tournament\" del juego de Nicky Case. Este módulo necesitará de inputs extra. Ten en cuenta lo siguiente:\n",
    " - La población inicial de jugadores no es directamente el input de jugadores que dé el usuario, sino que cada jugador tiene varios \"individuos\" o \"réplicas\" que jugarán su estrategia. El usuario podrá definir la población inicial de dos opciones (ambos mecanismos deben ser funcionales en tu implementación):\n",
    "   - Si el usuario define el tamaño de la población total (```int```), se asume que cada jugador comienza con el mismo número de representantes. Divide ese número entre el número de jugadores (redondeado al entero más próximo) y así obtendrás el número de individuos inicial de cada estrategia.\n",
    "   - Si el usuario define una tupla de números de individuos (```list[int, ...]```), se asume que cada jugador tendrá el número de representantes que indique su índice dentro de dicha tupla.\n",
    " - Hay dos parámetros más que controlan el proceso evolutivo. \n",
    "   - En primer lugar, el porcentaje de individuos que se desea incluir en la selección natural tras cada ronda; esto es, el número de individuos *de la parte de abajo del ranking* que se van a eliminar y sustituir por los *individuos de la parte de arriba* (en caso de empate entre individuos, escoge al azar).\n",
    "   - En segundo lugar, el número de generaciones que se van a simular. Una generación es básicamente un \"Torneo de enfrentamiento directo\" + un \"Proceso de selección natural\". \n",
    "\n",
    "El resto de decisiones de diseño que debas tomar son libres. A continuación se incluye la plantilla de desarrollo sugerida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evolution:\n",
    "\n",
    "    # Este método ya está implementado\n",
    "    def __init__(self, players: tuple[Player, ...],\n",
    "                       n_rounds: int = 100,\n",
    "                       error: float = 0.0,\n",
    "                       repetitions: int = 2,\n",
    "                       generations: int = 100,\n",
    "                       reproductivity: float = 0.05,\n",
    "                       initial_population: tuple[int, ...] | int = 100):\n",
    "        \"\"\"\n",
    "        Evolutionary tournament\n",
    "\n",
    "        Parameters:\n",
    "            - players (tuple[Player, ...]): tuple of players that will play the\n",
    "         tournament\n",
    "            - n_rounds (int = 100): number of rounds in each game\n",
    "            - error (float = 0.0): error probability (in base 1)\n",
    "            - repetitions (int = 2): number of games each player plays against\n",
    "         the rest\n",
    "            - generations (int = 100): number of generations to simulate\n",
    "            - reproductivity (float = 0.05): ratio (base 1) of worst players\n",
    "         that will be removed and substituted by the top ones in the natural\n",
    "         selection process carried out at the end of each generation\n",
    "            - initial_population (tuple[int, ...] | int = 100): list of\n",
    "         individuals representing each players (same index as 'players' tuple)\n",
    "         OR total population size (int).\n",
    "        \"\"\"\n",
    "\n",
    "        self.players = players\n",
    "        self.n_rounds = n_rounds\n",
    "        self.error = error\n",
    "        self.repetitions = repetitions\n",
    "        self.generations = generations\n",
    "        self.reproductivity = reproductivity\n",
    "\n",
    "        if isinstance(initial_population, int):\n",
    "            self.initial_population = [math.floor(initial_population\n",
    "                                       / len(self.players))\n",
    "                                       for _ in range(len(self.players))]\n",
    "        else:\n",
    "            self.initial_population = initial_population\n",
    "\n",
    "        self.total_population = sum(self.initial_population)\n",
    "        self.repr_int = int(self.total_population * self.reproductivity)\n",
    "\n",
    "        self.ranking = {copy.deepcopy(player): 0.0 for i, player in\n",
    "                        enumerate(self.players)\n",
    "                        for _ in range(self.initial_population[i])}\n",
    "\n",
    "\n",
    "    def natural_selection(self, result_tournament: dict[Player, float]) \\\n",
    "                          -> tuple[list,list]:\n",
    "        \"\"\"\n",
    "        Kill the worst guys, reproduce the top ones. Takes the ranking once a\n",
    "        face-to-face tournament has been played and returns another ranking,\n",
    "        with the evolutionary changes applied\n",
    "\n",
    "        Parameters:\n",
    "            - result_tournament: the 'tournament.ranking' kind of dict.\n",
    "\n",
    "        Results:\n",
    "            - Same kind of dict ranking as the input, but with the evolutionary\n",
    "         dynamics applied\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def count_strategies(self) -> dict[str, int]:\n",
    "        \"\"\"\n",
    "        Counts the number of played alive of each strategy, based on the\n",
    "        initial list of players. Should be computed analyzing the\n",
    "        'self.ranking' variable. Useful for the results plot/print (not needed\n",
    "        for the tournament itself)\n",
    "\n",
    "        Results:\n",
    "            - A dict, containing as values the name of the players and as\n",
    "         values the number of individuals they have now alive in the tournament\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    def play(self, do_print: bool = False):\n",
    "        \"\"\"\n",
    "        Main call of the class. Performs the computations to simulate the\n",
    "        evolutionary tournament.\n",
    "\n",
    "        Parameters\n",
    "            - do_print (bool = False): if True, should print the ongoing\n",
    "         results at the end of each generation (i.e. print generation number,\n",
    "         and number of individuals playing each strategy).\n",
    "        \"\"\"\n",
    "\n",
    "        # HINT: Initialise the following variable\n",
    "        #  > count_evolution = {player.name: [val] for player, val in\n",
    "        #                       zip(self.players, self.initial_population)}\n",
    "        # and use it to store the number of individuals each player retains at\n",
    "        # the end of each generation, appending to its corresponding list value\n",
    "        # the number of individuals each player has (obtained by calling\n",
    "        # 'self.count_strategies()'). For example, at some point, it could have\n",
    "        # the following value:\n",
    "        # {'always0': [15, 10, 5, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        #  'random': [5, 10, 15, 19, 14, 9, 4, 0, 0, 0, 0],\n",
    "        #  'focal5': [5, 5, 5, 6, 11, 16, 21, 25, 25, 25, 25]}\n",
    "\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # Si quieres obtener un buen gráfico de la evolución, puedes usar este\n",
    "    # método si has seguido la pista indicada en la cabecera del método\n",
    "    # anterior. Ya está implementado, pero puede que necesites adaptarlo a tu\n",
    "    # código.\n",
    "    def stackplot(self, count_evolution: dict[str, list]) -> None:\n",
    "        \"\"\"\n",
    "        Plots a 'stackplot' of the evolution of the tournament\n",
    "\n",
    "        Parameters:\n",
    "            - count_evolution (dict[Player, list]): a dictionary containing as\n",
    "         keys the name of the strategies of the different players of the\n",
    "         tournament. Each value is a list, where the 'i'-th position of that\n",
    "         list indicates the number of individuals that player has at the end of\n",
    "         the 'i'-th generation\n",
    "         \"\"\"\n",
    "\n",
    "        COLORS = ['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black']\n",
    "\n",
    "        for i, name in enumerate(count_evolution.keys()):\n",
    "            plt.plot([], [], label=name, color= COLORS[(i) % len(COLORS)])\n",
    "\n",
    "        plt.stackplot(list(range(self.generations + 1)),\n",
    "                      np.array(list(count_evolution.values())), colors=COLORS)\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para testear el módulo anterior, puedes experimentar con diferentes poblaciones iniciales de estrategias. Por ejemplo, un torneo evolutivo con estrategias Always0, UniformRandom y Focal5, sin error, con 10 rondas por interacción, con una reproductividad del 0.2. Observa qué estrategias dominan la población a lo largo de las generaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Game()\n",
    "\n",
    "always0_player = Always0(game, \"always0\")\n",
    "random_player = UniformRandom(game, \"random\")\n",
    "focal5_player = Focal5(game, \"focal5\")\n",
    "\n",
    "all_players = (always0_player, random_player, focal5_player)\n",
    "\n",
    "evolution = Evolution(all_players, n_rounds=10, error=0.00,\n",
    "                      repetitions=1, generations=10, reproductivity=0.2,\n",
    "                      initial_population=(15, 5, 5))\n",
    "\n",
    "evolution.play(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Enhorabuena! La primera parte de la práctica ya la has terminado. Ahora puedes experimentar todo lo que quieras con el juego de suma limitada iterado. Tú mismo has creado la herramienta para hacerlo. En la siguiente sección, tendrás que diseñar una estrategia para participar en un triple campeonato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: diseño de una estrategia\n",
    "\n",
    "A continuación deberás implementar una estrategia que se enfrentará a las de tus compañeros en un torneo del JCMA.\n",
    "\n",
    "Los juegos contra tus rivales tendrán un final **no determinista**. Esto quiere decir que el número de rondas que se van a jugar no se sabe con precisión. En lugar de eso, después de cada ronda, la partida tiene una cierta probabilidad de acabar (pequeña). ¿Por qué haremos esto? En juegos iterados con duración finita conocida, la proximidad del final juega un papel crucial en las decisiones estratégicas (e.g., incentivos a desertar en las últimas rondas).\n",
    "\n",
    "Con el objetivo de dejar esta complejidad adicional fuera, jugaremos un número de rondas aleatorio: puedes pensar que tu estrategia va a jugar \"muchas veces\" contra cada rival. **En media, se jugarán 100 rondas** (puedes quedarte con ese número). Los puntos obtenidos en cada interacción se normalizarán por el número de rondas jugadas para evitar sesgos por duración variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción del campeonato\n",
    "Ahora sí, vamos a ver las condiciones del torneo. Hay tres fases en esta competición:\n",
    " - Fase de enfrentamiento directo entre estrategias\n",
    " - Fase evolutiva\n",
    " - Fase evolutiva dentro del ecosistema completo del juego de suma limitada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Fase de enfrentamiento directo entre estrategias\n",
    "\n",
    "Se jugará un torneo de *todos contra todos*: te enfrentarás a las estrategias de tus rivales dos veces. El resultado que obtengas en cada enfrentamiento se sumará a los ya obtenidos hasta el momento. Ganará la estrategia con más puntos al final de las interacciones. Las condiciones concretas son las siguientes:\n",
    " - El JCMA que se usará será el definido anteriormente: acciones S={0,1,2,3,4,5}, umbral T=5, y payoffs u1(i,j)=i si i+j≤5, 0 si i+j>5 (análogamente para u2).\n",
    " - La probabilidad de acabar el enfrentamiento tras cada ronda $P_{end}$ se fija en 1%, con un máximo de rondas de 400.\n",
    " - La probabilidad de error $P_{error}$ se fija en 1%.\n",
    " - Se jugará 2 veces contra cada rival.\n",
    "\n",
    "Se asignarán los siguientes puntos según la posición final:\n",
    " - 5º y 6º clasificados: 4 puntos\n",
    " - 4º clasificado: 8 puntos\n",
    " - 3º clasificado: 12 puntos\n",
    " - 2º clasificado: 17 puntos\n",
    " - 1º clasificado: 24 puntos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Fase evolutiva\n",
    "\n",
    "Las estrategias se enfrentarán en un torneo evolutivo, en el que todos parten con el mismo número de representantes. Las condiciones para cada generación son las mismas que en la fase anterior. \n",
    "\n",
    "La reproductividad se manejará de forma ligeramente distinta a lo visto en secciones anteriores. Ahora, en sucesivas generaciones, la proporción de individuos de un jugador frente al total será la misma que la proporción de puntos obtenidos por todos esos individuos frente al total de puntos obtenidos por todas las estrategias. Por ejemplo, imagina que una determinada generación tienes 17 individuos de un total de 100. Estos individuos, en suma han obtenido un total de 210 puntos. Además, la suma de puntos obtenidos por todas las individuos de la población es 1000 puntos. Por tanto, en la siguiente generación dispondrás de 21 individuos.\n",
    "\n",
    "Aquí la evaluación de los ganadores puede ser complicada. En principio, el orden en el que se extingan las estrategias indicará el ranking de esta fase. No obstante, en ocasiones surgen situaciones difíciles de evaluar (por ejemplo, comportamientos cíclicos de dominancia de varias estrategias). En este tipo de escenarios, será el profesor decida qué estrategias han sido las más exitosas y su orden. Los puntos que pueden obtenerse en esta fase son los siguientes:\n",
    " - 3º clasificado: 12 puntos\n",
    " - 2º clasificado: 17 puntos\n",
    " - 1º clasificado: 24 puntos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fase evolutiva dentro de un ecosistema complejo del JCMA\n",
    "\n",
    "En esta fase, tu estrategia se enfrentará en un gran torneo evolutivo, donde estarán incluidas las estrategias de tus compañeros, pero también hasta 30 estrategias adicionales del ecosistema del JCMA. Estarán las que ya conoces (Always0, Focal5, TitForTat, etc.), y también estrategias adaptadas de la literatura de juegos de coordinación y bargaining. De nuevo, el criterio general para establecer el ranking entre nuestras estrategias será: \"cuanto más tarde se extingan tus individuos, más alto estarás en el ranking\". Al tener tantas estrategias, esta parte del campeonato es la más susceptible a presentar situaciones difíciles de evaluar, por lo que en última instancia será el profesor quien, partiendo de criterios objetivos, seleccione las tres estrategias más exitosas, que se llevarán:\n",
    " - 3º clasificado: 4 puntos\n",
    " - 2º clasificado: 8 puntos\n",
    " - 1º clasificado: 12 puntos\n",
    "\n",
    "Los puntos de las tres fases se sumarán y **el ganador obtendrá 1.5 puntos extra en la evaluación de esta práctica** (pudiendo obtener una nota superior a 10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación de tu estrategia\n",
    "\n",
    "A la hora de implementar tu estrategia ten en cuenta lo siguiente:\n",
    " - Si has seguido la plantilla de desarrollo de la primera parte de la práctica, tu estrategia deberá ser implementada como un subclase de la clase abstracta ```Player()```. En particular, debes implementar cuidadosamente su método ```strategy()```. \n",
    " - No olvides darle un buen nombre a tu estrategia. \n",
    " - Igualmente, mientras implementas, incluye todo los comentarios que puedan ayudar al profesor a evaluar positivamente tu estrategia. Por ejemplo: \"*he visto que mi estrategia funcionaba mal contra Focal5, por eso incluyo el siguiente bloque de código que pretende...*\". \n",
    " - **¡IMPORTANTE!** incluye información suficientemente extensa para explicar tus decisiones de diseño, por qué presentas esa estrategia y no otra, cuáles son los resultados que has observado en las pruebas que has hecho, qué problemas te has encontrado y cómo los has solucionado, etc. Incluye esta información en el docstring de la estrategia, en celdas posteriores o en un documento adjunto (e.g. pdf).\n",
    "\n",
    "A continuación se incluye un ejemplo de implementación de una estrategia. De echo, este ejemplo será la estrategia del profesor, ¡y participará en el campeonato! Así que ya sabes una de las estrategias que va a estar presente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrategia del Profesor\n",
    "class CastigadorInfernal(Player):\n",
    "    \"\"\"\n",
    "    Adaptive strategy for the limited-sum game that balances coordination and self-protection.\n",
    "\n",
    "    Strategy:\n",
    "    - Starts trying to coordinate on i+j=5 (efficient outcome)\n",
    "    - Monitors opponent's cooperation patterns and adapts accordingly\n",
    "    - Uses graduated punishment for greedy behavior\n",
    "    - Attempts forgiveness and cooperation recovery\n",
    "    - Adjusts strategy based on opponent's consistency\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, game: Game, name: str = \"\"):\n",
    "        super().__init__(game, name)\n",
    "        self.cooperation_score = 0  # Track opponent's cooperative behavior\n",
    "        self.punishment_mode = False\n",
    "        self.punishment_rounds = 0\n",
    "\n",
    "    def strategy(self, opponent: Player) -> int:\n",
    "        \"\"\"\n",
    "        Adaptive strategy with cooperation tracking and graduated response\n",
    "        \"\"\"\n",
    "        # First round: start with 2 (middle ground)\n",
    "        if not self.history:\n",
    "            return 2\n",
    "\n",
    "        last_opponent = opponent.history[-1]\n",
    "\n",
    "        # Update cooperation tracking\n",
    "        if last_opponent <= 3:\n",
    "            self.cooperation_score += 1\n",
    "        else:\n",
    "            self.cooperation_score -= 2\n",
    "\n",
    "        # Analyze opponent's recent pattern (last 5 rounds)\n",
    "        recent_rounds = min(5, len(opponent.history))\n",
    "        recent_actions = opponent.history[-recent_rounds:]\n",
    "        avg_recent = sum(recent_actions) / len(recent_actions)\n",
    "\n",
    "        # Simplified punishment mechanism\n",
    "        if self.punishment_mode:\n",
    "            self.punishment_rounds += 1\n",
    "            # Simple punishment: play 0 for 2 rounds, then try to recover\n",
    "            if self.punishment_rounds <= 2:\n",
    "                return 0\n",
    "            else:\n",
    "                # Reset and try to recover cooperation\n",
    "                self.punishment_mode = False\n",
    "                self.punishment_rounds = 0\n",
    "                return 2\n",
    "\n",
    "        # Detect consistently greedy behavior\n",
    "        if last_opponent > 3 and avg_recent > 3.5:\n",
    "            self.punishment_mode = True\n",
    "            self.punishment_rounds = 0\n",
    "            return 0\n",
    "\n",
    "        # Normal coordination attempt\n",
    "        if last_opponent <= 3:\n",
    "            # Try to maintain sum=5\n",
    "            return max(0, min(5, 5 - last_opponent))\n",
    "\n",
    "        # Default fallback\n",
    "        return 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Espacio para el desarrollo de tu estrategia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe en este comentario las personas que forman tu grupo !!!!!!!\n",
    "class NombreDeTuEstrategia(Player):\n",
    "\n",
    "    def __init__(self, game: Game, name: str = \"\"):\n",
    "        \"\"\"\n",
    "        Describe aquí el propósito de tu estrategia, motivación, y cómo has explorado dinámicas\n",
    "        de cooperación/equidad en el juego de suma limitada iterado. Explica decisiones de diseño,\n",
    "        pruebas realizadas, y cómo se diferencia de estrategias básicas.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def strategy(self, opponent: Player) -> int:\n",
    "        \"\"\"\n",
    "        Implementa la lógica de tu estrategia basada en el historial (self.history, opponent.history).\n",
    "        Devuelve una acción entera entre 0 y 5.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haz todas las pruebas que necesites aquí.\n",
    "# No es necesario que las conserves para la entrega (basta con que las expliques)\n",
    "# Por ejemplo:\n",
    "#\n",
    "# game = Game(Always0(game, \"always0\"), UniformRandom(game, \"random\"),\n",
    "#             n_rounds=10, error=0.1)\n",
    "# game.play(do_print=True)\n",
    "#\n",
    "# O también:\n",
    "#\n",
    "# participants = (Always0(game, \"always0\"),\n",
    "#                 Always3(game, \"always3\"),\n",
    "#                 UniformRandom(game, \"random\"),\n",
    "#                 Focal5(game, \"focal5\"))\n",
    "#\n",
    "# tournament = Tournament(participants, n_rounds=100, error=0.01,\n",
    "#                         repetitions=2)\n",
    "# tournament.play()\n",
    "# tournament.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consideraciones logísticas sobre la práctica\n",
    "- Asegúrate que el código funciona correctamente antes de entregarlo. En particular, asegúrate de que tu estrategias siempre devuelve una acción, independientemente de cómo sea la historia de la interacción. Así mismo, asegúrate de que el código está programado con un buen estilo. \n",
    "En particular, utiliza *type hints*, documenta los métodos que escribas, y comenta las secciones relevantes del código.\n",
    "\n",
    "- Debéis desarrollar el código vosotros mismos, no utilizar código ya disponible (online o en librerías). Los trabajos de los grupos que no hayan desarrollado el código ellos mismos, o que hayan pasado su código a otras personas, serán evaluados con un 0.\n",
    "\n",
    "- Esta hoja de trabajo incluye todos los conceptos necesarios para desarrollar la práctica. Si tienes alguna pregunta, no dudes en utilizar las tutorías del curso para resolverla. Hay muchísima bibliografía online sobre juegos de coordinación y bargaining, aunque en absoluto es necesario consultarla: las dinámicas de cada campeonato dependen fuertemente de las personas que participan en él. Lo realmente útil es que pienses en qué tipo de estrategias crees que van a presentar tus rivales y hagas suficientes pruebas. \n",
    "\n",
    "- Si trabajas en proyecto, puedes compartirlo como zip o mediante link de github."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
